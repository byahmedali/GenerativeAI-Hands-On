{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87e5b680-4e25-4b75-aa64-5b8c64375544",
   "metadata": {},
   "source": [
    "# **Ollama Local Models**\n",
    "\n",
    "[Ollama](https://ollama.com/) allows you to run open-source large language models, such as Llama 2, locally.\n",
    "\n",
    "For a complete list of supported models and model variants, see the [Ollama model library](https://ollama.com/search).\n",
    "\n",
    "We will chat with locally running reasoning LLM, `deepseek-r1:1.5b` as an example.\n",
    "\n",
    "Make sure Ollama is installed & running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f4b1d-7e08-4ba4-8ad9-a5ec51bcb7e3",
   "metadata": {},
   "source": [
    "## Simple Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e326e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Greetings! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. How may I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "def ChatOllama(prompt):\n",
    "    response: ChatResponse = chat(model='deepseek-r1:1.5b',\n",
    "    messages=[\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': prompt,\n",
    "    }\n",
    "    ])\n",
    "    return response\n",
    "\n",
    "chat_response = ChatOllama(\"Introduce yourself.\")\n",
    "print(chat_response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052dd45-06ab-47c1-9f9e-07c74e2a032c",
   "metadata": {},
   "source": [
    "## Explain text to a 5 year old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5e20632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I just read this explanation about Ollama, which is a tool that lets you run open-source large language models like Llama 2. The user wanted me to explain it to a five-year-old who's learning AI. Hmm, that's interesting. \n",
      "\n",
      "First off, I need to make sure my explanation is simple and engaging for a child. I should avoid any technical jargon or complicated terms because they might not understand what \"deepseek-r1\" even means right away. Maybe using something like \"big model\" instead of \"large language models\" would be better.\n",
      "\n",
      "I also notice that the user provided specific instructions on how to use Ollama, like running `deepseek-r1:1.5b` as an example. That's important because it shows exactly what they can do with it. But I have to remember not to tell them too much about those models without explaining why or in a way that makes sense to a child.\n",
      "\n",
      "Wait, the user mentioned model variants like \"r1\" and \"llm\". Maybe I should explain what each part means. Like, maybe break down words so they understand terms like \"r1\" as a specific version or variant of the model. That could help them grasp more advanced features later if they're curious.\n",
      "\n",
      "I also think about how to make their example interactive for a child. Instead of just talking about `deepseek-r1:1.5b`, perhaps show them how to use the tool and what happens when they run it. That hands-on experience is key, especially since they're still learning new concepts.\n",
      "\n",
      "Oh, I should also emphasize that Ollama can be fun because it's a simple yet powerful tool for exploring AI. Maybe compare it to other cool apps or toys that let kids play with ideas and see what happens when they do things like build towers or race cars. That analogy might make the concept more relatable.\n",
      "\n",
      "I wonder if I should mention anything about how big Ollama is in terms of size, but since it's just a tool for education, maybe not too detailed. Just acknowledge that it can be used on any computer or even your phone because it doesn't require special hardware.\n",
      "\n",
      "Overall, my goal is to make the explanation clear and engaging while keeping it simple. I should use lots of examples and analogies they can easily understand. It's all about making sure they see that learning AI isn't just about reading a book but being able to play with some cool digital toys.\n",
      "</think>\n",
      "\n",
      "Sure! Let me explain Ollama in a way that's fun and easy for you to understand:\n",
      "\n",
      "**Ollama** is like a superpower tool that lets you build amazing stories and conversations on your computer or even a phone. Itâ€™s not just for grown-ups thoughâ€”it can help you explore AI, which is like when computers learn from data and improve with more information.\n",
      "\n",
      "Let me show you how it works: You type something, like \"Hello!\" and Ollama gets in the middle of a conversation with me! Cool, right?  \n",
      "\n",
      "If I give you `deepseek-r1:1.5b`, thatâ€™s like telling me which big model to use. Itâ€™s super powerful because itâ€™s designed to handle lots of different questions and ideas. You can ask it all sorts of funny questions or explore the world together!\n",
      "\n",
      "So Ollama is a tool for playing with AI, building stories, and making fun experiments. Itâ€™s simple but powerful! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"[Ollama](https://ollama.com/) allows you to run open-source large language models, such as Llama 2, locally.\n",
    "\n",
    "For a complete list of supported models and model variants, see the [Ollama model library](https://ollama.com/search).\n",
    "\n",
    "We will chat with locally running `deepseek-r1:1.5b` as an example.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"Explain the provided input text as you are teaching a 5 year old learning AI.\n",
    "Input_text: {input_text}\n",
    "\"\"\"\n",
    "\n",
    "response = ChatOllama(prompt)\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76b569-ecca-492a-ba9e-f539e6e0ef33",
   "metadata": {},
   "source": [
    "## Streaming Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abcf74ff-ad60-4da7-95ec-36e6a3a75252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, the user just asked me to introduce myself. Okay, so I need to come up with a response that shows I'm friendly and professional.\n",
      "\n",
      "I should start by greeting them warmly. Something like \"Hello! How can I assist you today?\" That sounds natural.\n",
      "\n",
      "Next, I'll mention my name and where I am. Mentioning my current role or position would show I'm ready to help someone they might be looking for.\n",
      "\n",
      "Then, I need to explain what I can do. Since the topic was introduced earlier, maybe I should offer help with specific things like math problems, writing, or something else they might need assistance with.\n",
      "\n",
      "I'll keep it conversational and open-ended so they know I'm here to help further.\n",
      "</think>\n",
      "\n",
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "def OllamaStreamChat(prompt):\n",
    "    stream = chat(\n",
    "        model = 'deepseek-r1:1.5b',\n",
    "        messages = [{'role': 'user', 'content': prompt}],\n",
    "        stream = True\n",
    "    )\n",
    "\n",
    "    for chunk in stream:\n",
    "        print(chunk['message']['content'], end='', flush=True)\n",
    "\n",
    "prompt = \"Introduce yourself.\"\n",
    "OllamaStreamChat(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
